**Python-Implementation-of-Vanishing-Gradient-Problem**

**Overview**

This repository contains practical example of Vanishing Gradient Problem in Recurrent Neural Networks (RNNs) and how Long Short-Term Memory (LSTM) networks help to mitigate this issue.

I have created a sample text data , then I convert text to numerical token to feed into machine learning model

Afterthat I have created two model RNNs & LSTM , where we can see  difference between gradient behaviour of two model.

**Installation** 

Clone the repository:  
git clone https://github.com/MasudRana2406/Python-Implementation-of-Vanishing-Gradient-Problem.git


Pull requests are welcome! Please follow these steps:  
1. Fork the repository  
2. Create a new branch (`git checkout -b feature-branch`)  
3. Commit your changes (`git commit -m "Add feature"`)  
4. Push to the branch (`git push origin feature-branch`)  
5. Open a Pull Request


**License**

This project is licensed under the Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ file for details.

